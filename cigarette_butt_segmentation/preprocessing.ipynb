{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как входные данные состоят из массивов (512, 512, 3), то обучение данных затратит больших вычислительных можностей. Именно поэтому мы отрезайзим входную фотографи и маску в размер (256, 256). Так как данных много и они большого размера, то лучше не загружать их всех в оперативную память, а делать это порциями. Кроме того, нормируем наши данные на 255 для улучшения обучения модели. Все это реализуем в генераторе keras_generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator(path, batch_size):\n",
    "\n",
    "        \n",
    "    while True:\n",
    "        images = os.listdir(f\"{path}/images\")\n",
    "        annotations = json.load(open(f\"{path}/coco_annotations.json\", \"r\"))\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            img_id = int(np.random.choice(images).split(\".\")[0])\n",
    "            img = np.array(Image.open(f\"{path}/images/{img_id:08}.jpg\"))\n",
    "            mask = get_mask(img_id, annotations)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            \n",
    "            x_batch += [img]\n",
    "            y_batch += [mask]\n",
    "\n",
    "        x_batch = np.array(x_batch) / 255.\n",
    "        y_batch = np.array(y_batch) /255.\n",
    "\n",
    "        yield x_batch, np.expand_dims(y_batch, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично напишем функции для загрузки валидационных данных и тестовых:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка валидационных данных для проверки\n",
    "def load_data(path, batch_size):\n",
    "\n",
    "    annotations = json.load(open(f\"{path}/coco_annotations.json\", \"r\"))    \n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for i in range(batch_size):\n",
    "            img_id = i\n",
    "            img = np.array(Image.open(f\"{path}/images/{img_id:08}.jpg\"))\n",
    "            mask = get_mask(img_id, annotations)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            \n",
    "            x_batch += [img]\n",
    "            y_batch += [mask]\n",
    "        x_batch = np.array(x_batch) / 255.\n",
    "\n",
    "        return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка тестовых данных для проверки\n",
    "def get_test(path, batch_size):\n",
    "    x_batch = []\n",
    "    for i in range(batch_size):\n",
    "        img_id = i\n",
    "        img = np.array(Image.open(f\"{path}/real_test/images/{img_id:04}.jpg\"))\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        x_batch += [img]\n",
    "\n",
    "    x_batch = np.array(x_batch) / 255.\n",
    "    return x_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в звязи с тем, что мы работаем с изображениями 256x256, нам необходимо их преобразовать обратно в 512x512:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конвектируем маску в 512x512\n",
    "def det_mask(pred, val):\n",
    "    A= np.zeros((256, 256))\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            if (pred[i,j,0] > val):\n",
    "                A[i,j]=1\n",
    "    A = cv2.resize(A, (512, 512))\n",
    "    \n",
    "    for i in range(512):\n",
    "        for j in range(512):\n",
    "            if (A[i,j] != 1):\n",
    "                A[i,j]=0\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за некорректного сохранения изображений пришлось писать свою немного измененную функцию зохранения:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#кастомная функция для сохранения изображений, связвнная с роботой модели на изображениях (256x256)\n",
    "def save_html_new(paths_to_imgs, pred_masks, path_to_save=\"results/test\"):\n",
    "    \n",
    "    paths_to_imgs = np.array(paths_to_imgs)\n",
    "    pred_masks = np.array(pred_masks)\n",
    "\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    order = np.argsort(paths_to_imgs)\n",
    "    paths_to_imgs = paths_to_imgs[order]\n",
    "    pred_masks = pred_masks[order]\n",
    "\n",
    "    for path_to_img, pred_mask in zip(paths_to_imgs, pred_masks):\n",
    "        img_id = path_to_img.split(\"/\")[-1].split(\".\")[0]\n",
    "        img = np.array(Image.open(path_to_img))[:, :, :3]\n",
    "        Image.fromarray(img).save(f\"{path_to_save}/{img_id}_img.jpg\")\n",
    "        rle_mask = encode_rle(pred_mask)\n",
    "        decoded_mask = decode_rle(rle_mask)\n",
    "        Image.fromarray(decoded_mask).save(f\"{path_to_save}/{img_id}_pred_mask.png\")\n",
    "        crop_img = img.copy()\n",
    "        crop_img[pred_mask == 0] = 0\n",
    "        Image.fromarray(crop_img).save(f\"{path_to_save}/{img_id}_crop.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментации:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения обучения модели помимо входные данные будим их также изменять пораждая тем дополнительный датасет для обучегия.\n",
    " Реализовано в функции strong_aug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_aug(p=1.0):\n",
    "    return Compose([\n",
    "        ShiftScaleRotate(shift_limit=0.125, scale_limit=0.2, rotate_limit=10, p=0.7, border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomCrop(256, 256),\n",
    "        #PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
    "        #Resize(64, 64),\n",
    "        #RandomRotate90(),\n",
    "        ElasticTransform(1.), \n",
    "        #HorizontalFlip(),\n",
    "        #Cutout(p=1.),\n",
    "        #Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.3),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.4),\n",
    "            MedianBlur(blur_limit=3, p=0.3),\n",
    "            Blur(blur_limit=3, p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=3),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomContrast(),\n",
    "            RandomBrightness(),\n",
    "        ], p=0.4),\n",
    "        HueSaturationValue(p=0.7),\n",
    "         \n",
    "        \n",
    "        \n",
    "    ],\n",
    "        p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
